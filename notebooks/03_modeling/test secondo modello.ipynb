{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-01-29T15:54:06.510452Z",
     "start_time": "2026-01-29T15:54:01.066290Z"
    }
   },
   "source": [
    "# ======================================================\n",
    "# MODELLO 2 ‚Äî XGBOOST (SAME DATASET AS MODEL 1)\n",
    "# TRAIN + VALIDATION ONLY ‚Äî NO TEST SET\n",
    "# ======================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    recall_score,\n",
    "    precision_score,\n",
    "    f1_score\n",
    ")\n",
    "\n",
    "# ======================================================\n",
    "# 1Ô∏è‚É£ PATH (STESSI DEL MODELLO 1)\n",
    "# ======================================================\n",
    "\n",
    "TRAIN_PATH = \"/Users/marcodonatiello/PycharmProjects/JupyterProject/data/interim/splits/train_step5.csv\"\n",
    "VAL_PATH = \"/Users/marcodonatiello/PycharmProjects/JupyterProject/data/interim/splits/val_step5.csv\"\n",
    "\n",
    "TARGET = \"IS_SEVERE\"\n",
    "\n",
    "# ======================================================\n",
    "# 2Ô∏è‚É£ LOAD DATA\n",
    "# ======================================================\n",
    "\n",
    "train = pd.read_csv(TRAIN_PATH)\n",
    "val = pd.read_csv(VAL_PATH)\n",
    "\n",
    "print(\"Train shape:\", train.shape)\n",
    "print(\"Val shape:\", val.shape)\n",
    "\n",
    "# ======================================================\n",
    "# 3Ô∏è‚É£ SPLIT FEATURES / TARGET\n",
    "# ======================================================\n",
    "\n",
    "X_train = train.drop(columns=[TARGET])\n",
    "y_train = train[TARGET]\n",
    "\n",
    "X_val = val.drop(columns=[TARGET])\n",
    "y_val = val[TARGET]\n",
    "\n",
    "print(\"\\nTarget distribution (train):\")\n",
    "print(y_train.value_counts(normalize=True))\n",
    "\n",
    "print(\"\\nTarget distribution (val):\")\n",
    "print(y_val.value_counts(normalize=True))\n",
    "\n",
    "# ======================================================\n",
    "# 4Ô∏è‚É£ SCALE POSITIVE CLASS (CLASS IMBALANCE)\n",
    "# ======================================================\n",
    "\n",
    "scale_pos_weight = (y_train == 0).sum() / (y_train == 1).sum()\n",
    "print(\"\\nscale_pos_weight:\", scale_pos_weight)\n",
    "\n",
    "# ======================================================\n",
    "# 5Ô∏è‚É£ MODELLO XGBOOST\n",
    "# ======================================================\n",
    "\n",
    "model = XGBClassifier(\n",
    "    n_estimators=400,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    scale_pos_weight=scale_pos_weight,\n",
    "    objective=\"binary:logistic\",\n",
    "    eval_metric=\"logloss\",\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\n‚úÖ Modello XGBoost addestrato\")\n",
    "\n",
    "# ======================================================\n",
    "# 6Ô∏è‚É£ VALIDATION ‚Äî SOGLIA DECISIONALE\n",
    "# ======================================================\n",
    "\n",
    "THRESHOLD = 0.30  # üëà di solito XGB lavora bene con soglie pi√π basse\n",
    "\n",
    "val_probs = model.predict_proba(X_val)[:, 1]\n",
    "val_pred = (val_probs >= THRESHOLD).astype(int)\n",
    "\n",
    "# ======================================================\n",
    "# 7Ô∏è‚É£ METRICHE FINALI\n",
    "# ======================================================\n",
    "\n",
    "print(\"\\nüìä CLASSIFICATION REPORT (VALIDATION)\")\n",
    "print(classification_report(y_val, val_pred, digits=4))\n",
    "\n",
    "print(\"üìâ CONFUSION MATRIX\")\n",
    "print(confusion_matrix(y_val, val_pred))\n",
    "\n",
    "print(\"\\nüéØ CLASSE SEVERA (1)\")\n",
    "print(\"Recall    :\", recall_score(y_val, val_pred))\n",
    "print(\"Precision :\", precision_score(y_val, val_pred))\n",
    "print(\"F1-score  :\", f1_score(y_val, val_pred))\n",
    "\n",
    "false_negatives = ((y_val == 1) & (val_pred == 0)).sum()\n",
    "false_positives = ((y_val == 0) & (val_pred == 1)).sum()\n",
    "\n",
    "print(\"\\n‚ùó Errori critici\")\n",
    "print(\"False Negatives (severi persi):\", false_negatives)\n",
    "print(\"False Positives:\", false_positives)\n",
    "\n",
    "print(\"\\nüîí MODELLO 2 COMPLETATO ‚Äî TEST SET NON UTILIZZATO\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (536370, 78)\n",
      "Val shape: (134093, 78)\n",
      "\n",
      "Target distribution (train):\n",
      "IS_SEVERE\n",
      "0    0.871577\n",
      "1    0.128423\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Target distribution (val):\n",
      "IS_SEVERE\n",
      "0    0.871574\n",
      "1    0.128426\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "scale_pos_weight: 6.786794808513109\n",
      "\n",
      "‚úÖ Modello XGBoost addestrato\n",
      "\n",
      "üìä CLASSIFICATION REPORT (VALIDATION)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9817    0.7096    0.8238    116872\n",
      "           1     0.3159    0.9101    0.4690     17221\n",
      "\n",
      "    accuracy                         0.7353    134093\n",
      "   macro avg     0.6488    0.8099    0.6464    134093\n",
      "weighted avg     0.8962    0.7353    0.7782    134093\n",
      "\n",
      "üìâ CONFUSION MATRIX\n",
      "[[82932 33940]\n",
      " [ 1548 15673]]\n",
      "\n",
      "üéØ CLASSE SEVERA (1)\n",
      "Recall    : 0.910109749724174\n",
      "Precision : 0.31590510551669926\n",
      "F1-score  : 0.4690127779274022\n",
      "\n",
      "‚ùó Errori critici\n",
      "False Negatives (severi persi): 1548\n",
      "False Positives: 33940\n",
      "\n",
      "üîí MODELLO 2 COMPLETATO ‚Äî TEST SET NON UTILIZZATO\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-29T16:04:37.822026Z",
     "start_time": "2026-01-29T16:04:13.336637Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ======================================================\n",
    "# STAGE 2 ‚Äî STACKING ENSEMBLE (RF + XGB ‚Üí META MODEL)\n",
    "# ======================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    recall_score,\n",
    "    precision_score,\n",
    "    f1_score\n",
    ")\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# ======================================================\n",
    "# 1Ô∏è‚É£ PATH\n",
    "# ======================================================\n",
    "\n",
    "TRAIN_PATH = \"/Users/marcodonatiello/PycharmProjects/JupyterProject/data/interim/splits/train_step5.csv\"\n",
    "VAL_PATH   = \"/Users/marcodonatiello/PycharmProjects/JupyterProject/data/interim/splits/val_step5.csv\"\n",
    "\n",
    "TARGET = \"IS_SEVERE\"\n",
    "\n",
    "# ======================================================\n",
    "# 2Ô∏è‚É£ LOAD DATA\n",
    "# ======================================================\n",
    "\n",
    "train = pd.read_csv(TRAIN_PATH)\n",
    "val   = pd.read_csv(VAL_PATH)\n",
    "\n",
    "X_train = train.drop(columns=[TARGET])\n",
    "y_train = train[TARGET]\n",
    "\n",
    "X_val = val.drop(columns=[TARGET])\n",
    "y_val = val[TARGET]\n",
    "\n",
    "print(\"Train shape:\", X_train.shape)\n",
    "print(\"Val shape:\", X_val.shape)\n",
    "\n",
    "# ======================================================\n",
    "# 3Ô∏è‚É£ CLASS IMBALANCE\n",
    "# ======================================================\n",
    "\n",
    "scale_pos_weight = (y_train == 0).sum() / (y_train == 1).sum()\n",
    "print(\"scale_pos_weight:\", scale_pos_weight)\n",
    "\n",
    "# ======================================================\n",
    "# 4Ô∏è‚É£ BASE MODELS (LEVEL 0)\n",
    "# ======================================================\n",
    "\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=15,\n",
    "    min_samples_leaf=10,\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    "    class_weight=\"balanced\"\n",
    ")\n",
    "\n",
    "xgb = XGBClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    scale_pos_weight=scale_pos_weight,\n",
    "    eval_metric=\"logloss\",\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"\\nüöÄ Training base models...\")\n",
    "rf.fit(X_train, y_train)\n",
    "xgb.fit(X_train, y_train)\n",
    "\n",
    "print(\"‚úÖ Base models trained\")\n",
    "\n",
    "# ======================================================\n",
    "# 5Ô∏è‚É£ META-FEATURES\n",
    "# ======================================================\n",
    "# Usiamo SOLO le probabilit√† della classe severa (1)\n",
    "\n",
    "train_meta = pd.DataFrame({\n",
    "    \"rf_prob\":  rf.predict_proba(X_train)[:, 1],\n",
    "    \"xgb_prob\": xgb.predict_proba(X_train)[:, 1]\n",
    "})\n",
    "\n",
    "val_meta = pd.DataFrame({\n",
    "    \"rf_prob\":  rf.predict_proba(X_val)[:, 1],\n",
    "    \"xgb_prob\": xgb.predict_proba(X_val)[:, 1]\n",
    "})\n",
    "\n",
    "# ======================================================\n",
    "# 6Ô∏è‚É£ META-MODEL (LEVEL 1)\n",
    "# ======================================================\n",
    "\n",
    "meta_model = LogisticRegression(\n",
    "    class_weight=\"balanced\",\n",
    "    max_iter=1000,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"\\nüöÄ Training meta-model...\")\n",
    "meta_model.fit(train_meta, y_train)\n",
    "\n",
    "print(\"‚úÖ Meta-model trained\")\n",
    "\n",
    "# ======================================================\n",
    "# 7Ô∏è‚É£ PREDICTION (STACKING)\n",
    "# ======================================================\n",
    "\n",
    "THRESHOLD = 0.35  # ‚Üê REGOLABILE\n",
    "\n",
    "val_probs = meta_model.predict_proba(val_meta)[:, 1]\n",
    "val_pred  = (val_probs >= THRESHOLD).astype(int)\n",
    "\n",
    "# ======================================================\n",
    "# 8Ô∏è‚É£ METRICHE FINALI\n",
    "# ======================================================\n",
    "\n",
    "print(\"\\nüìä CLASSIFICATION REPORT (STACKING ‚Äî VALIDATION)\")\n",
    "print(classification_report(y_val, val_pred, digits=4))\n",
    "\n",
    "print(\"üìâ CONFUSION MATRIX\")\n",
    "print(confusion_matrix(y_val, val_pred))\n",
    "\n",
    "print(\"\\nüéØ CLASSE SEVERA (1)\")\n",
    "print(\"Recall    :\", recall_score(y_val, val_pred))\n",
    "print(\"Precision :\", precision_score(y_val, val_pred))\n",
    "print(\"F1-score  :\", f1_score(y_val, val_pred))\n",
    "\n",
    "false_negatives = ((y_val == 1) & (val_pred == 0)).sum()\n",
    "false_positives = ((y_val == 0) & (val_pred == 1)).sum()\n",
    "\n",
    "print(\"\\n‚ùó Errori critici\")\n",
    "print(\"False Negatives:\", false_negatives)\n",
    "print(\"False Positives:\", false_positives)\n",
    "\n",
    "print(\"\\nüèÜ STACKING COMPLETATO ‚Äî TEST SET NON UTILIZZATO\")\n",
    "\n"
   ],
   "id": "baf8537d569f90ce",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (536370, 77)\n",
      "Val shape: (134093, 77)\n",
      "scale_pos_weight: 6.786794808513109\n",
      "\n",
      "üöÄ Training base models...\n",
      "‚úÖ Base models trained\n",
      "\n",
      "üöÄ Training meta-model...\n",
      "‚úÖ Meta-model trained\n",
      "\n",
      "üìä CLASSIFICATION REPORT (STACKING ‚Äî VALIDATION)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9770    0.7686    0.8603    116872\n",
      "           1     0.3584    0.8772    0.5088     17221\n",
      "\n",
      "    accuracy                         0.7825    134093\n",
      "   macro avg     0.6677    0.8229    0.6846    134093\n",
      "weighted avg     0.8976    0.7825    0.8152    134093\n",
      "\n",
      "üìâ CONFUSION MATRIX\n",
      "[[89822 27050]\n",
      " [ 2114 15107]]\n",
      "\n",
      "üéØ CLASSE SEVERA (1)\n",
      "Recall    : 0.877242901109111\n",
      "Precision : 0.3583509262993097\n",
      "F1-score  : 0.508841658526727\n",
      "\n",
      "‚ùó Errori critici\n",
      "False Negatives: 2114\n",
      "False Positives: 27050\n",
      "\n",
      "üèÜ STACKING COMPLETATO ‚Äî TEST SET NON UTILIZZATO\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "587b68f7cecd9341"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-29T16:10:15.273372Z",
     "start_time": "2026-01-29T16:10:15.107516Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    recall_score,\n",
    "    precision_score,\n",
    "    f1_score,\n",
    "    confusion_matrix\n",
    ")\n",
    "\n",
    "# ======================================================\n",
    "# 1Ô∏è‚É£ PROBABILIT√Ä STACKING SU VALIDATION\n",
    "# ======================================================\n",
    "\n",
    "val_probs = meta_model.predict_proba(X_val_meta)[:, 1]\n",
    "\n",
    "# ======================================================\n",
    "# 2Ô∏è‚É£ SWEEP SOGLIA\n",
    "# ======================================================\n",
    "\n",
    "thresholds = np.arange(0.20, 0.51, 0.05)\n",
    "\n",
    "rows = []\n",
    "\n",
    "for th in thresholds:\n",
    "    val_pred = (val_probs >= th).astype(int)\n",
    "\n",
    "    recall = recall_score(y_val, val_pred)\n",
    "    precision = precision_score(y_val, val_pred)\n",
    "    f1 = f1_score(y_val, val_pred)\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(y_val, val_pred).ravel()\n",
    "\n",
    "    rows.append({\n",
    "        \"threshold\": th,\n",
    "        \"recall\": recall,\n",
    "        \"precision\": precision,\n",
    "        \"f1\": f1,\n",
    "        \"false_negatives\": fn,\n",
    "        \"false_positives\": fp\n",
    "    })\n",
    "\n",
    "results = pd.DataFrame(rows)\n",
    "\n",
    "# ======================================================\n",
    "# 3Ô∏è‚É£ RISULTATI\n",
    "# ======================================================\n",
    "\n",
    "print(\"\\nüìä TUNING SOGLIA ‚Äî STACKING (VALIDATION ONLY)\")\n",
    "print(results)\n",
    "\n",
    "# ======================================================\n",
    "# 4Ô∏è‚É£ FILTRO CONSIGLIATO (recall minimo)\n",
    "# ======================================================\n",
    "\n",
    "print(\"\\nüéØ Soglie con Recall ‚â• 0.88\")\n",
    "print(results[results[\"recall\"] >= 0.88])\n"
   ],
   "id": "e5df732badbc3727",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_val_meta' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNameError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[3]\u001B[39m\u001B[32m, line 15\u001B[39m\n\u001B[32m      4\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01msklearn\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mmetrics\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[32m      5\u001B[39m     recall_score,\n\u001B[32m      6\u001B[39m     precision_score,\n\u001B[32m      7\u001B[39m     f1_score,\n\u001B[32m      8\u001B[39m     confusion_matrix\n\u001B[32m      9\u001B[39m )\n\u001B[32m     11\u001B[39m \u001B[38;5;66;03m# ======================================================\u001B[39;00m\n\u001B[32m     12\u001B[39m \u001B[38;5;66;03m# 1Ô∏è‚É£ PROBABILIT√Ä STACKING SU VALIDATION\u001B[39;00m\n\u001B[32m     13\u001B[39m \u001B[38;5;66;03m# ======================================================\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m15\u001B[39m val_probs = meta_model.predict_proba(\u001B[43mX_val_meta\u001B[49m)[:, \u001B[32m1\u001B[39m]\n\u001B[32m     17\u001B[39m \u001B[38;5;66;03m# ======================================================\u001B[39;00m\n\u001B[32m     18\u001B[39m \u001B[38;5;66;03m# 2Ô∏è‚É£ SWEEP SOGLIA\u001B[39;00m\n\u001B[32m     19\u001B[39m \u001B[38;5;66;03m# ======================================================\u001B[39;00m\n\u001B[32m     21\u001B[39m thresholds = np.arange(\u001B[32m0.20\u001B[39m, \u001B[32m0.51\u001B[39m, \u001B[32m0.05\u001B[39m)\n",
      "\u001B[31mNameError\u001B[39m: name 'X_val_meta' is not defined"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-30T18:18:36.149476Z",
     "start_time": "2026-01-30T18:16:42.871137Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ======================================================\n",
    "# STAGE 2 ‚Äî STACKING ENSEMBLE (OOF, NO LEAKAGE)\n",
    "# RF + XGB ‚Üí META MODEL\n",
    "# ======================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    recall_score,\n",
    "    precision_score,\n",
    "    f1_score\n",
    ")\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# ======================================================\n",
    "# 1Ô∏è‚É£ PATH\n",
    "# ======================================================\n",
    "\n",
    "TRAIN_PATH = \"/Users/marcodonatiello/PycharmProjects/JupyterProject/data/interim/splits/train_step6.csv\"\n",
    "VAL_PATH   = \"/Users/marcodonatiello/PycharmProjects/JupyterProject/data/interim/splits/val_step6.csv\"\n",
    "\n",
    "TARGET = \"IS_SEVERE\"\n",
    "\n",
    "# ======================================================\n",
    "# 2Ô∏è‚É£ LOAD DATA\n",
    "# ======================================================\n",
    "\n",
    "train = pd.read_csv(TRAIN_PATH)\n",
    "val   = pd.read_csv(VAL_PATH)\n",
    "\n",
    "X_train = train.drop(columns=[TARGET])\n",
    "y_train = train[TARGET]\n",
    "\n",
    "X_val = val.drop(columns=[TARGET])\n",
    "y_val = val[TARGET]\n",
    "\n",
    "print(\"Train shape:\", X_train.shape)\n",
    "print(\"Val shape:\", X_val.shape)\n",
    "\n",
    "# ======================================================\n",
    "# 3Ô∏è‚É£ CLASS IMBALANCE\n",
    "# ======================================================\n",
    "\n",
    "scale_pos_weight = (y_train == 0).sum() / (y_train == 1).sum()\n",
    "print(\"scale_pos_weight:\", scale_pos_weight)\n",
    "\n",
    "# ======================================================\n",
    "# 4Ô∏è‚É£ OOF META-FEATURES (TRAIN)\n",
    "# ======================================================\n",
    "\n",
    "skf = StratifiedKFold(\n",
    "    n_splits=5,\n",
    "    shuffle=True,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "train_meta = pd.DataFrame(\n",
    "    index=X_train.index,\n",
    "    columns=[\"rf_prob\", \"xgb_prob\"]\n",
    ")\n",
    "\n",
    "print(\"\\nüöÄ Generating OOF meta-features...\")\n",
    "\n",
    "for fold, (tr_idx, va_idx) in enumerate(skf.split(X_train, y_train), 1):\n",
    "    print(f\"Fold {fold}\")\n",
    "\n",
    "    X_tr, X_va = X_train.iloc[tr_idx], X_train.iloc[va_idx]\n",
    "    y_tr = y_train.iloc[tr_idx]\n",
    "\n",
    "    rf = RandomForestClassifier(\n",
    "        n_estimators=300,\n",
    "        max_depth=15,\n",
    "        min_samples_leaf=10,\n",
    "        n_jobs=-1,\n",
    "        random_state=42,\n",
    "        class_weight=\"balanced\"\n",
    "    )\n",
    "\n",
    "    xgb = XGBClassifier(\n",
    "        n_estimators=300,\n",
    "        max_depth=6,\n",
    "        learning_rate=0.05,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        scale_pos_weight=scale_pos_weight,\n",
    "        eval_metric=\"logloss\",\n",
    "        n_jobs=-1,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    rf.fit(X_tr, y_tr)\n",
    "    xgb.fit(X_tr, y_tr)\n",
    "\n",
    "    train_meta.loc[X_va.index, \"rf_prob\"]  = rf.predict_proba(X_va)[:, 1]\n",
    "    train_meta.loc[X_va.index, \"xgb_prob\"] = xgb.predict_proba(X_va)[:, 1]\n",
    "\n",
    "train_meta = train_meta.astype(float)\n",
    "\n",
    "print(\"‚úÖ OOF meta-features generated\")\n",
    "\n",
    "# ======================================================\n",
    "# 5Ô∏è‚É£ FIT BASE MODELS SU TUTTO TRAIN (PER VALIDATION)\n",
    "# ======================================================\n",
    "\n",
    "rf_final = RandomForestClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=15,\n",
    "    min_samples_leaf=10,\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    "    class_weight=\"balanced\"\n",
    ")\n",
    "\n",
    "xgb_final = XGBClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    scale_pos_weight=scale_pos_weight,\n",
    "    eval_metric=\"logloss\",\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"\\nüöÄ Training base models on FULL TRAIN...\")\n",
    "rf_final.fit(X_train, y_train)\n",
    "xgb_final.fit(X_train, y_train)\n",
    "print(\"‚úÖ Base models trained\")\n",
    "\n",
    "# ======================================================\n",
    "# 6Ô∏è‚É£ META-FEATURES (VALIDATION)\n",
    "# ======================================================\n",
    "\n",
    "val_meta = pd.DataFrame({\n",
    "    \"rf_prob\":  rf_final.predict_proba(X_val)[:, 1],\n",
    "    \"xgb_prob\": xgb_final.predict_proba(X_val)[:, 1]\n",
    "})\n",
    "\n",
    "# ======================================================\n",
    "# 7Ô∏è‚É£ META-MODEL\n",
    "# ======================================================\n",
    "\n",
    "meta_model = LogisticRegression(\n",
    "    class_weight=\"balanced\",\n",
    "    max_iter=1000,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"\\nüöÄ Training meta-model...\")\n",
    "meta_model.fit(train_meta, y_train)\n",
    "print(\"‚úÖ Meta-model trained\")\n",
    "\n",
    "# ======================================================\n",
    "# 8Ô∏è‚É£ PREDICTION (STACKING)\n",
    "# ======================================================\n",
    "\n",
    "THRESHOLD = 0.60   # ‚Üê REGOLABILE\n",
    "\n",
    "val_probs = meta_model.predict_proba(val_meta)[:, 1]\n",
    "val_pred  = (val_probs >= THRESHOLD).astype(int)\n",
    "\n",
    "# ======================================================\n",
    "# 9Ô∏è‚É£ METRICHE FINALI\n",
    "# ======================================================\n",
    "\n",
    "print(\"\\nüìä CLASSIFICATION REPORT (STACKING ‚Äî VALIDATION)\")\n",
    "print(classification_report(y_val, val_pred, digits=4))\n",
    "\n",
    "print(\"üìâ CONFUSION MATRIX\")\n",
    "print(confusion_matrix(y_val, val_pred))\n",
    "\n",
    "print(\"\\nüéØ CLASSE SEVERA (1)\")\n",
    "print(\"Recall    :\", recall_score(y_val, val_pred))\n",
    "print(\"Precision :\", precision_score(y_val, val_pred))\n",
    "print(\"F1-score  :\", f1_score(y_val, val_pred))\n",
    "\n",
    "false_negatives = ((y_val == 1) & (val_pred == 0)).sum()\n",
    "false_positives = ((y_val == 0) & (val_pred == 1)).sum()\n",
    "\n",
    "print(\"\\n‚ùó Errori critici\")\n",
    "print(\"False Negatives:\", false_negatives)\n",
    "print(\"False Positives:\", false_positives)\n",
    "\n",
    "print(\"\\nüèÜ STACKING OOF COMPLETATO ‚Äî TEST SET NON UTILIZZATO\")\n"
   ],
   "id": "11d52fa54cb8664",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (536370, 78)\n",
      "Val shape: (134093, 78)\n",
      "scale_pos_weight: 6.786794808513109\n",
      "\n",
      "üöÄ Generating OOF meta-features...\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "‚úÖ OOF meta-features generated\n",
      "\n",
      "üöÄ Training base models on FULL TRAIN...\n",
      "‚úÖ Base models trained\n",
      "\n",
      "üöÄ Training meta-model...\n",
      "‚úÖ Meta-model trained\n",
      "\n",
      "üìä CLASSIFICATION REPORT (STACKING ‚Äî VALIDATION)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9658    0.8609    0.9103    116872\n",
      "           1     0.4565    0.7928    0.5794     17221\n",
      "\n",
      "    accuracy                         0.8522    134093\n",
      "   macro avg     0.7111    0.8269    0.7449    134093\n",
      "weighted avg     0.9004    0.8522    0.8678    134093\n",
      "\n",
      "üìâ CONFUSION MATRIX\n",
      "[[100620  16252]\n",
      " [  3568  13653]]\n",
      "\n",
      "üéØ CLASSE SEVERA (1)\n",
      "Recall    : 0.792811102723419\n",
      "Precision : 0.45654572813910715\n",
      "F1-score  : 0.5794253702839197\n",
      "\n",
      "‚ùó Errori critici\n",
      "False Negatives: 3568\n",
      "False Positives: 16252\n",
      "\n",
      "üèÜ STACKING OOF COMPLETATO ‚Äî TEST SET NON UTILIZZATO\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "4b412ebd29d53991"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-29T16:30:59.270688Z",
     "start_time": "2026-01-29T16:30:58.781897Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ======================================================\n",
    "# THRESHOLD TUNING ‚Äî STACKING META-MODEL\n",
    "# ======================================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    recall_score,\n",
    "    precision_score,\n",
    "    f1_score,\n",
    "    confusion_matrix,\n",
    "    classification_report\n",
    ")\n",
    "\n",
    "# ======================================================\n",
    "# 1Ô∏è‚É£ PROBABILIT√Ä DEL META-MODEL (VALIDATION)\n",
    "# ======================================================\n",
    "\n",
    "val_probs = meta_model.predict_proba(val_meta)[:, 1]\n",
    "\n",
    "# ======================================================\n",
    "# 2Ô∏è‚É£ SWEEP DELLE SOGLIE\n",
    "# ======================================================\n",
    "\n",
    "thresholds = np.arange(0.10, 0.61, 0.02)\n",
    "results = []\n",
    "\n",
    "for t in thresholds:\n",
    "    val_pred = (val_probs >= t).astype(int)\n",
    "\n",
    "    recall = recall_score(y_val, val_pred)\n",
    "    precision = precision_score(y_val, val_pred)\n",
    "    f1 = f1_score(y_val, val_pred)\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(y_val, val_pred).ravel()\n",
    "\n",
    "    results.append({\n",
    "        \"threshold\": round(t, 2),\n",
    "        \"recall\": recall,\n",
    "        \"precision\": precision,\n",
    "        \"f1\": f1,\n",
    "        \"false_negatives\": fn,\n",
    "        \"false_positives\": fp\n",
    "    })\n",
    "\n",
    "# ======================================================\n",
    "# 3Ô∏è‚É£ RISULTATI ORDINATI\n",
    "# ======================================================\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "results_df = results_df.sort_values(\n",
    "    by=\"f1\", ascending=False\n",
    ").reset_index(drop=True)\n",
    "\n",
    "print(\"\\nüìä THRESHOLD TUNING RESULTS (sorted by F1)\\n\")\n",
    "print(results_df.head(15))\n",
    "\n",
    "# ======================================================\n",
    "# 4Ô∏è‚É£ SOGLIA MIGLIORE (AUTOMATICA)\n",
    "# ======================================================\n",
    "\n",
    "best = results_df.iloc[0]\n",
    "\n",
    "BEST_THRESHOLD = best[\"threshold\"]\n",
    "\n",
    "print(\"\\nüèÜ BEST THRESHOLD SELECTED\")\n",
    "print(\"Threshold       :\", BEST_THRESHOLD)\n",
    "print(\"Recall          :\", round(best[\"recall\"], 4))\n",
    "print(\"Precision       :\", round(best[\"precision\"], 4))\n",
    "print(\"F1-score        :\", round(best[\"f1\"], 4))\n",
    "print(\"False Negatives :\", int(best[\"false_negatives\"]))\n",
    "print(\"False Positives :\", int(best[\"false_positives\"]))\n",
    "\n",
    "# ======================================================\n",
    "# 5Ô∏è‚É£ METRICHE FINALI CON SOGLIA SCELTA\n",
    "# ======================================================\n",
    "\n",
    "final_pred = (val_probs >= BEST_THRESHOLD).astype(int)\n",
    "\n",
    "print(\"\\nüìâ CONFUSION MATRIX (FINAL)\")\n",
    "print(confusion_matrix(y_val, final_pred))\n",
    "\n",
    "print(\"\\nüìä CLASSIFICATION REPORT (FINAL)\\n\")\n",
    "print(classification_report(y_val, final_pred, digits=4))\n",
    "\n",
    "# ======================================================\n",
    "# 6Ô∏è‚É£ ANALISI ALTERNATIVA (OPZIONALE)\n",
    "# ======================================================\n",
    "\n",
    "print(\"\\nüîé TOP 5 SOGLIE ‚Äî MIN FALSE NEGATIVES\\n\")\n",
    "print(\n",
    "    results_df.sort_values(\n",
    "        by=[\"false_negatives\", \"false_positives\"]\n",
    "    ).head(5)\n",
    ")\n",
    "\n",
    "print(\"\\nüîé TOP 5 SOGLIE ‚Äî MIN FALSE POSITIVES\\n\")\n",
    "print(\n",
    "    results_df.sort_values(\n",
    "        by=[\"false_positives\", \"false_negatives\"]\n",
    "    ).head(5)\n",
    ")\n",
    "\n",
    "print(\"\\n‚úÖ THRESHOLD TUNING COMPLETATO\")\n"
   ],
   "id": "1816c596f68354bb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä THRESHOLD TUNING RESULTS (sorted by F1)\n",
      "\n",
      "    threshold    recall  precision        f1  false_negatives  false_positives\n",
      "0        0.60  0.791650   0.459860  0.581774             3588            16013\n",
      "1        0.58  0.800418   0.449635  0.575809             3437            16872\n",
      "2        0.56  0.809012   0.440245  0.570201             3289            17714\n",
      "3        0.54  0.817432   0.431003  0.564412             3144            18584\n",
      "4        0.52  0.824981   0.422387  0.558715             3014            19428\n",
      "5        0.50  0.832007   0.414715  0.553525             2893            20221\n",
      "6        0.48  0.838395   0.407014  0.547994             2783            21035\n",
      "7        0.46  0.843853   0.399308  0.542097             2689            21861\n",
      "8        0.44  0.849486   0.390732  0.535263             2592            22811\n",
      "9        0.42  0.856919   0.383010  0.529399             2464            23772\n",
      "10       0.40  0.863887   0.376233  0.524179             2344            24665\n",
      "11       0.38  0.870217   0.368523  0.517776             2235            25679\n",
      "12       0.36  0.875733   0.360582  0.510831             2140            26743\n",
      "13       0.34  0.882237   0.353202  0.504449             2028            27822\n",
      "14       0.32  0.888450   0.345365  0.497383             1921            29001\n",
      "\n",
      "üèÜ BEST THRESHOLD SELECTED\n",
      "Threshold       : 0.6\n",
      "Recall          : 0.7916\n",
      "Precision       : 0.4599\n",
      "F1-score        : 0.5818\n",
      "False Negatives : 3588\n",
      "False Positives : 16013\n",
      "\n",
      "üìâ CONFUSION MATRIX (FINAL)\n",
      "[[100859  16013]\n",
      " [  3588  13633]]\n",
      "\n",
      "üìä CLASSIFICATION REPORT (FINAL)\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9656    0.8630    0.9114    116872\n",
      "           1     0.4599    0.7916    0.5818     17221\n",
      "\n",
      "    accuracy                         0.8538    134093\n",
      "   macro avg     0.7128    0.8273    0.7466    134093\n",
      "weighted avg     0.9007    0.8538    0.8691    134093\n",
      "\n",
      "\n",
      "üîé TOP 5 SOGLIE ‚Äî MIN FALSE NEGATIVES\n",
      "\n",
      "    threshold    recall  precision        f1  false_negatives  false_positives\n",
      "25       0.10  0.976482   0.205962  0.340174              405            64830\n",
      "24       0.12  0.964694   0.229912  0.371327              608            55645\n",
      "23       0.14  0.953835   0.247339  0.392816              795            49985\n",
      "22       0.16  0.945241   0.262502  0.410895              943            45733\n",
      "21       0.18  0.935834   0.276229  0.426552             1105            42227\n",
      "\n",
      "üîé TOP 5 SOGLIE ‚Äî MIN FALSE POSITIVES\n",
      "\n",
      "   threshold    recall  precision        f1  false_negatives  false_positives\n",
      "0       0.60  0.791650   0.459860  0.581774             3588            16013\n",
      "1       0.58  0.800418   0.449635  0.575809             3437            16872\n",
      "2       0.56  0.809012   0.440245  0.570201             3289            17714\n",
      "3       0.54  0.817432   0.431003  0.564412             3144            18584\n",
      "4       0.52  0.824981   0.422387  0.558715             3014            19428\n",
      "\n",
      "‚úÖ THRESHOLD TUNING COMPLETATO\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-30T18:29:06.869136Z",
     "start_time": "2026-01-30T18:27:18.143630Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ======================================================\n",
    "# STACKING MODEL ‚Äî TRAINING & EVALUATION\n",
    "# ======================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    recall_score,\n",
    "    precision_score,\n",
    "    f1_score\n",
    ")\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# ======================================================\n",
    "# 1Ô∏è‚É£ PATH & PARAMS\n",
    "# ======================================================\n",
    "\n",
    "TRAIN_PATH = \"/Users/marcodonatiello/PycharmProjects/JupyterProject/data/interim/splits/train_step5.csv\"\n",
    "VAL_PATH   = \"/Users/marcodonatiello/PycharmProjects/JupyterProject/data/interim/splits/val_step5.csv\"\n",
    "\n",
    "TARGET = \"IS_SEVERE\"\n",
    "THRESHOLD = 0.60   # soglia scelta dal tuning\n",
    "\n",
    "# ======================================================\n",
    "# 2Ô∏è‚É£ LOAD DATA\n",
    "# ======================================================\n",
    "\n",
    "train = pd.read_csv(TRAIN_PATH)\n",
    "val   = pd.read_csv(VAL_PATH)\n",
    "\n",
    "X_train = train.drop(columns=[TARGET])\n",
    "y_train = train[TARGET]\n",
    "\n",
    "X_val = val.drop(columns=[TARGET])\n",
    "y_val = val[TARGET]\n",
    "\n",
    "print(\"Train shape:\", X_train.shape)\n",
    "print(\"Val shape  :\", X_val.shape)\n",
    "\n",
    "# ======================================================\n",
    "# 3Ô∏è‚É£ CLASS IMBALANCE\n",
    "# ======================================================\n",
    "\n",
    "scale_pos_weight = (y_train == 0).sum() / (y_train == 1).sum()\n",
    "print(\"scale_pos_weight:\", scale_pos_weight)\n",
    "\n",
    "# ======================================================\n",
    "# 4Ô∏è‚É£ BASE MODELS (LEVEL 0)\n",
    "# ======================================================\n",
    "\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=15,\n",
    "    min_samples_leaf=10,\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    "    class_weight=\"balanced\"\n",
    ")\n",
    "\n",
    "xgb = XGBClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    scale_pos_weight=scale_pos_weight,\n",
    "    eval_metric=\"logloss\",\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# ======================================================\n",
    "# 5Ô∏è‚É£ OOF META-FEATURES (TRAIN)\n",
    "# ======================================================\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "train_meta = np.zeros((len(train), 2))\n",
    "\n",
    "print(\"\\nüöÄ Generating OOF meta-features...\")\n",
    "for fold, (tr_idx, val_idx) in enumerate(skf.split(X_train, y_train), 1):\n",
    "    print(f\"Fold {fold}\")\n",
    "\n",
    "    rf.fit(X_train.iloc[tr_idx], y_train.iloc[tr_idx])\n",
    "    xgb.fit(X_train.iloc[tr_idx], y_train.iloc[tr_idx])\n",
    "\n",
    "    train_meta[val_idx, 0] = rf.predict_proba(X_train.iloc[val_idx])[:, 1]\n",
    "    train_meta[val_idx, 1] = xgb.predict_proba(X_train.iloc[val_idx])[:, 1]\n",
    "\n",
    "print(\"‚úÖ OOF meta-features generated\")\n",
    "\n",
    "# ======================================================\n",
    "# 6Ô∏è‚É£ TRAIN BASE MODELS ON FULL TRAIN\n",
    "# ======================================================\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "xgb.fit(X_train, y_train)\n",
    "\n",
    "val_meta = pd.DataFrame({\n",
    "    \"rf_prob\":  rf.predict_proba(X_val)[:, 1],\n",
    "    \"xgb_prob\": xgb.predict_proba(X_val)[:, 1]\n",
    "})\n",
    "\n",
    "# ======================================================\n",
    "# 7Ô∏è‚É£ META-MODEL (LEVEL 1)\n",
    "# ======================================================\n",
    "\n",
    "meta_model = LogisticRegression(\n",
    "    class_weight=\"balanced\",\n",
    "    max_iter=1000,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"\\nüöÄ Training meta-model...\")\n",
    "meta_model.fit(train_meta, y_train)\n",
    "print(\"‚úÖ Meta-model trained\")\n",
    "\n",
    "# ======================================================\n",
    "# 8Ô∏è‚É£ FINAL PREDICTIONS\n",
    "# ======================================================\n",
    "\n",
    "val_probs = meta_model.predict_proba(val_meta)[:, 1]\n",
    "val_pred  = (val_probs >= THRESHOLD).astype(int)\n",
    "\n",
    "# ======================================================\n",
    "# 9Ô∏è‚É£ METRICHE DI VALUTAZIONE\n",
    "# ======================================================\n",
    "\n",
    "print(\"\\nüìä CLASSIFICATION REPORT (STACKING ‚Äî VALIDATION)\")\n",
    "print(classification_report(y_val, val_pred, digits=4))\n",
    "\n",
    "print(\"üìâ CONFUSION MATRIX\")\n",
    "print(confusion_matrix(y_val, val_pred))\n",
    "\n",
    "print(\"\\nüéØ CLASSE SEVERA (1)\")\n",
    "print(\"Recall    :\", recall_score(y_val, val_pred))\n",
    "print(\"Precision :\", precision_score(y_val, val_pred))\n",
    "print(\"F1-score  :\", f1_score(y_val, val_pred))\n",
    "\n",
    "false_negatives = ((y_val == 1) & (val_pred == 0)).sum()\n",
    "false_positives = ((y_val == 0) & (val_pred == 1)).sum()\n",
    "\n",
    "print(\"\\n‚ùó Errori critici\")\n",
    "print(\"False Negatives:\", false_negatives)\n",
    "print(\"False Positives:\", false_positives)\n",
    "\n",
    "print(\"\\nüèÜ STACKING MODEL EVALUATION COMPLETATA ‚Äî TEST SET NON UTILIZZATO\")\n"
   ],
   "id": "4d0002ed562ae89d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (536370, 77)\n",
      "Val shape: (134093, 77)\n",
      "scale_pos_weight: 6.786794808513109\n",
      "\n",
      "üöÄ Generating OOF meta-features...\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "‚úÖ OOF meta-features generated\n",
      "\n",
      "üìâ FALSE NEGATIVES: 3588\n",
      "‚úÖ TRUE POSITIVES : 13633\n",
      "\n",
      "üîç TOP 15 DIFFERENZE NUMERICHE (FN vs TP)\n",
      "                      feature     FN_mean     TP_mean  delta_FN_minus_TP\n",
      "74      fc_age_x_num_symptoms  233.008082  514.838040        -281.829958\n",
      "1                     NUMDAYS   11.154682  152.600748        -141.446066\n",
      "0                     AGE_YRS   51.372074   65.675933         -14.303860\n",
      "75  fc_history_x_num_symptoms    4.664716    8.260471          -3.595755\n",
      "3              NUMERO_SINTOMI    4.664716    8.260471          -3.595755\n",
      "76   fc_age_x_history_cardiac    0.116778    0.830118          -0.713340\n",
      "68       num_symp_respiratory    0.115385    0.497103          -0.381718\n",
      "2             VAX_DOSE_SERIES    1.612040    1.849703          -0.237663\n",
      "5                       SEX_M    0.307971    0.534952          -0.226981\n",
      "4                       SEX_F    0.692029    0.465048           0.226981\n",
      "73             num_symp_total    0.700111    0.918653          -0.218542\n",
      "67           symp_respiratory    0.103122    0.314604          -0.211483\n",
      "70        num_symp_neurologic    0.296823    0.139734           0.157088\n",
      "69            symp_neurologic    0.248606    0.117802           0.130804\n",
      "72             num_symp_fever    0.197324    0.109954           0.087371\n",
      "\n",
      "üìä FN ‚Äî DISTRIBUZIONE PROBABILIT√Ä\n",
      "prob_bucket\n",
      "very_low      0.350056\n",
      "borderline    0.346711\n",
      "low           0.303233\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "üìÅ FILE SALVATI:\n",
      "- false_negatives.csv\n",
      "- true_positives_sample.csv\n",
      "\n",
      "üèÅ FN ANALYSIS COMPLETATA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marcodonatiello/PycharmProjects/JupyterProject/.venv/lib/python3.14/site-packages/sklearn/utils/validation.py:2684: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "6e4c794d877616e4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-30T18:26:51.877863Z",
     "start_time": "2026-01-30T18:26:47.759257Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ======================================================\n",
    "# PATH\n",
    "# ======================================================\n",
    "\n",
    "TRAIN_PATH = \"/Users/marcodonatiello/PycharmProjects/JupyterProject/data/interim/splits/train_step5.csv\"\n",
    "VAL_PATH   = \"/Users/marcodonatiello/PycharmProjects/JupyterProject/data/interim/splits/val_step5.csv\"\n",
    "\n",
    "OUT_TRAIN = \"/Users/marcodonatiello/PycharmProjects/JupyterProject/data/interim/splits/train_step6.csv\"\n",
    "OUT_VAL   = \"/Users/marcodonatiello/PycharmProjects/JupyterProject/data/interim/splits/val_step6.csv\"\n",
    "\n",
    "# ======================================================\n",
    "# LOAD DATA\n",
    "# ======================================================\n",
    "\n",
    "train = pd.read_csv(TRAIN_PATH)\n",
    "val   = pd.read_csv(VAL_PATH)\n",
    "\n",
    "print(\"Train shape (before):\", train.shape)\n",
    "print(\"Val shape   (before):\", val.shape)\n",
    "\n",
    "# ======================================================\n",
    "# FEATURE ENGINEERING\n",
    "# ratio_symp_respiratory\n",
    "# ======================================================\n",
    "\n",
    "def add_ratio_feature(df):\n",
    "    df[\"ratio_symp_respiratory\"] = (\n",
    "        df[\"num_symp_respiratory\"] /\n",
    "        df[\"num_symp_total\"].replace(0, np.nan)\n",
    "    )\n",
    "    df[\"ratio_symp_respiratory\"] = df[\"ratio_symp_respiratory\"].fillna(0)\n",
    "    return df\n",
    "\n",
    "train = add_ratio_feature(train)\n",
    "val   = add_ratio_feature(val)\n",
    "\n",
    "print(\"Train shape (after):\", train.shape)\n",
    "print(\"Val shape   (after):\", val.shape)\n",
    "\n",
    "# ======================================================\n",
    "# SAVE\n",
    "# ======================================================\n",
    "\n",
    "train.to_csv(OUT_TRAIN, index=False)\n",
    "val.to_csv(OUT_VAL, index=False)\n",
    "\n",
    "print(\"\\n‚úÖ DATASET STEP 6 CREATO\")\n",
    "print(\"Train:\", OUT_TRAIN)\n",
    "print(\"Val  :\", OUT_VAL)\n",
    "print(\"‚ùå Test set NON toccato\")\n"
   ],
   "id": "b26431d178dc3cc5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape (before): (536370, 78)\n",
      "Val shape   (before): (134093, 78)\n",
      "Train shape (after): (536370, 79)\n",
      "Val shape   (after): (134093, 79)\n",
      "\n",
      "‚úÖ DATASET STEP 6 CREATO\n",
      "Train: /Users/marcodonatiello/PycharmProjects/JupyterProject/data/interim/splits/train_step6.csv\n",
      "Val  : /Users/marcodonatiello/PycharmProjects/JupyterProject/data/interim/splits/val_step6.csv\n",
      "‚ùå Test set NON toccato\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-30T20:06:50.896971Z",
     "start_time": "2026-01-30T19:52:54.202129Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ======================================================\n",
    "# FULL PIPELINE: TUNING -> STACKING -> PRODUCTION EXPORT\n",
    "# ======================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    recall_score,\n",
    "    precision_score,\n",
    "    f1_score\n",
    ")\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# ======================================================\n",
    "# 1Ô∏è‚É£ CONFIGURAZIONE & PATH\n",
    "# ======================================================\n",
    "\n",
    "# Sostituisci con i tuoi percorsi reali\n",
    "TRAIN_PATH = \"/Users/marcodonatiello/PycharmProjects/JupyterProject/data/interim/splits/train_step6.csv\"\n",
    "VAL_PATH   = \"/Users/marcodonatiello/PycharmProjects/JupyterProject/data/interim/splits/val_step6.csv\"\n",
    "OUTPUT_MODEL_NAME = \"severe_model_stacking_production.pkl\"\n",
    "\n",
    "TARGET = \"IS_SEVERE\"\n",
    "N_SPLITS = 5\n",
    "SEED = 42\n",
    "\n",
    "# Quante combinazioni di parametri provare per ogni modello?\n",
    "# Metti 10 per un test veloce, 50+ per il risultato definitivo.\n",
    "N_ITER_SEARCH = 10\n",
    "\n",
    "# Soglie da testare nel post-processing\n",
    "THRESHOLDS = np.arange(0.20, 0.61, 0.02)\n",
    "\n",
    "# ======================================================\n",
    "# 2Ô∏è‚É£ CARICAMENTO DATI\n",
    "# ======================================================\n",
    "\n",
    "print(\"üìÇ Caricamento dataset...\")\n",
    "train = pd.read_csv(TRAIN_PATH)\n",
    "val   = pd.read_csv(VAL_PATH)\n",
    "\n",
    "X_train = train.drop(columns=[TARGET])\n",
    "y_train = train[TARGET]\n",
    "\n",
    "X_val = val.drop(columns=[TARGET])\n",
    "y_val = val[TARGET]\n",
    "\n",
    "# Calcolo sbilanciamento per XGB/LGBM\n",
    "scale_pos_weight = (y_train == 0).sum() / (y_train == 1).sum()\n",
    "print(f\"‚úÖ Dati caricati. Scale Pos Weight calcolato: {scale_pos_weight:.2f}\")\n",
    "\n",
    "# ======================================================\n",
    "# 3Ô∏è‚É£ HYPERPARAMETER TUNING (FASE NUOVA)\n",
    "# ======================================================\n",
    "# Questa fase cerca i parametri migliori invece di usarne di casuali.\n",
    "\n",
    "print(f\"\\n‚öôÔ∏è AVVIO TUNING (n_iter={N_ITER_SEARCH})... attendere...\")\n",
    "\n",
    "# --- A. Tuning Random Forest ---\n",
    "rf_params_dist = {\n",
    "    'n_estimators': [100, 200, 300, 400],\n",
    "    'max_depth': [10, 15, 20, 30, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'class_weight': ['balanced', 'balanced_subsample']\n",
    "}\n",
    "\n",
    "print(\"   ...Tuning Random Forest...\")\n",
    "rf_search = RandomizedSearchCV(\n",
    "    RandomForestClassifier(random_state=SEED, n_jobs=-1),\n",
    "    param_distributions=rf_params_dist,\n",
    "    n_iter=N_ITER_SEARCH,\n",
    "    scoring='f1', # O 'roc_auc' a seconda di cosa preferisci\n",
    "    cv=3,\n",
    "    n_jobs=-1,\n",
    "    random_state=SEED,\n",
    "    verbose=0\n",
    ")\n",
    "rf_search.fit(X_train, y_train)\n",
    "best_rf_params = rf_search.best_params_\n",
    "print(f\"   ‚úÖ Best RF Params: {best_rf_params}\")\n",
    "\n",
    "# --- B. Tuning XGBoost ---\n",
    "xgb_params_dist = {\n",
    "    'n_estimators': [100, 200, 300, 500],\n",
    "    'max_depth': [3, 5, 6, 8, 10],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "    'scale_pos_weight': [scale_pos_weight] # Fisso o varia leggermente\n",
    "}\n",
    "\n",
    "print(\"   ...Tuning XGBoost...\")\n",
    "xgb_search = RandomizedSearchCV(\n",
    "    XGBClassifier(eval_metric=\"logloss\", use_label_encoder=False, random_state=SEED, n_jobs=-1),\n",
    "    param_distributions=xgb_params_dist,\n",
    "    n_iter=N_ITER_SEARCH,\n",
    "    scoring='f1',\n",
    "    cv=3,\n",
    "    n_jobs=-1,\n",
    "    random_state=SEED,\n",
    "    verbose=0\n",
    ")\n",
    "xgb_search.fit(X_train, y_train)\n",
    "best_xgb_params = xgb_search.best_params_\n",
    "print(f\"   ‚úÖ Best XGB Params: {best_xgb_params}\")\n",
    "\n",
    "# --- C. Tuning LightGBM ---\n",
    "lgbm_params_dist = {\n",
    "    'n_estimators': [200, 400, 600],\n",
    "    'num_leaves': [31, 50, 64, 80],\n",
    "    'max_depth': [-1, 10, 20],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'subsample': [0.7, 0.8, 0.9],\n",
    "    'colsample_bytree': [0.7, 0.8, 0.9],\n",
    "    'class_weight': ['balanced']\n",
    "}\n",
    "\n",
    "print(\"   ...Tuning LightGBM...\")\n",
    "lgbm_search = RandomizedSearchCV(\n",
    "    LGBMClassifier(random_state=SEED, n_jobs=-1, verbose=-1),\n",
    "    param_distributions=lgbm_params_dist,\n",
    "    n_iter=N_ITER_SEARCH,\n",
    "    scoring='f1',\n",
    "    cv=3,\n",
    "    n_jobs=-1,\n",
    "    random_state=SEED,\n",
    "    verbose=0\n",
    ")\n",
    "lgbm_search.fit(X_train, y_train)\n",
    "best_lgbm_params = lgbm_search.best_params_\n",
    "print(f\"   ‚úÖ Best LGBM Params: {best_lgbm_params}\")\n",
    "\n",
    "# ======================================================\n",
    "# 4Ô∏è‚É£ INIZIALIZZAZIONE MODELLI (CON PARAMETRI OTTIMIZZATI)\n",
    "# ======================================================\n",
    "\n",
    "print(\"\\nüöÄ Inizializzazione modelli con i parametri migliori...\")\n",
    "\n",
    "rf = RandomForestClassifier(**best_rf_params, random_state=SEED, n_jobs=-1)\n",
    "xgb = XGBClassifier(**best_xgb_params, eval_metric=\"logloss\", random_state=SEED, n_jobs=-1)\n",
    "lgbm = LGBMClassifier(**best_lgbm_params, random_state=SEED, n_jobs=-1, verbose=-1)\n",
    "\n",
    "# ======================================================\n",
    "# 5Ô∏è‚É£ GENERAZIONE META-FEATURES (STACKING)\n",
    "# ======================================================\n",
    "\n",
    "skf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)\n",
    "\n",
    "train_meta = pd.DataFrame(np.zeros((len(train), 3)), columns=[\"rf_prob\", \"xgb_prob\", \"lgbm_prob\"])\n",
    "\n",
    "print(\"\\nüîÑ Generazione OOF meta-features (Training Livello 0)...\")\n",
    "\n",
    "for fold, (tr_idx, val_idx) in enumerate(skf.split(X_train, y_train), 1):\n",
    "    X_tr_fold, y_tr_fold = X_train.iloc[tr_idx], y_train.iloc[tr_idx]\n",
    "    X_val_fold = X_train.iloc[val_idx]\n",
    "\n",
    "    # Fit su fold corrente\n",
    "    rf.fit(X_tr_fold, y_tr_fold)\n",
    "    xgb.fit(X_tr_fold, y_tr_fold)\n",
    "    lgbm.fit(X_tr_fold, y_tr_fold)\n",
    "\n",
    "    # Previsioni out-of-fold\n",
    "    train_meta.iloc[val_idx, 0] = rf.predict_proba(X_val_fold)[:, 1]\n",
    "    train_meta.iloc[val_idx, 1] = xgb.predict_proba(X_val_fold)[:, 1]\n",
    "    train_meta.iloc[val_idx, 2] = lgbm.predict_proba(X_val_fold)[:, 1]\n",
    "\n",
    "    print(f\"   -> Fold {fold}/{N_SPLITS} completato\")\n",
    "\n",
    "# ======================================================\n",
    "# 6Ô∏è‚É£ ADDESTRAMENTO FINALE BASE MODELS (FULL TRAIN)\n",
    "# ======================================================\n",
    "# Ora che abbiamo le meta-features, ri-addestriamo i modelli base\n",
    "# su TUTTO il train set per averli pronti per la validazione e la produzione.\n",
    "\n",
    "print(\"\\nüèãÔ∏è Addestramento modelli base su tutto il dataset...\")\n",
    "rf.fit(X_train, y_train)\n",
    "xgb.fit(X_train, y_train)\n",
    "lgbm.fit(X_train, y_train)\n",
    "\n",
    "# Creiamo le meta-features per il validation set\n",
    "val_meta = pd.DataFrame({\n",
    "    \"rf_prob\": rf.predict_proba(X_val)[:, 1],\n",
    "    \"xgb_prob\": xgb.predict_proba(X_val)[:, 1],\n",
    "    \"lgbm_prob\": lgbm.predict_proba(X_val)[:, 1]\n",
    "})\n",
    "\n",
    "# ======================================================\n",
    "# 7Ô∏è‚É£ ADDESTRAMENTO META-MODEL & TUNING SOGLIA\n",
    "# ======================================================\n",
    "\n",
    "meta_model = LogisticRegression(class_weight=\"balanced\", max_iter=1000, random_state=SEED)\n",
    "meta_model.fit(train_meta, y_train)\n",
    "print(\"‚úÖ Meta-model addestrato\")\n",
    "\n",
    "# Probabilit√† finali sul validation set\n",
    "val_probs = meta_model.predict_proba(val_meta)[:, 1]\n",
    "\n",
    "# Ricerca soglia ottimale\n",
    "rows = []\n",
    "for t in THRESHOLDS:\n",
    "    pred = (val_probs >= t).astype(int)\n",
    "    rows.append({\n",
    "        \"threshold\": t,\n",
    "        \"f1\": f1_score(y_val, pred),\n",
    "        \"recall\": recall_score(y_val, pred),\n",
    "        \"precision\": precision_score(y_val, pred)\n",
    "    })\n",
    "\n",
    "thr_df = pd.DataFrame(rows).sort_values(\"f1\", ascending=False)\n",
    "BEST_T = thr_df.iloc[0][\"threshold\"]\n",
    "BEST_F1 = thr_df.iloc[0][\"f1\"]\n",
    "\n",
    "print(f\"\\nüèÜ BEST THRESHOLD: {BEST_T:.2f} (F1-Score: {BEST_F1:.4f})\")\n",
    "\n",
    "# ======================================================\n",
    "# 8Ô∏è‚É£ REPORT FINALE\n",
    "# ======================================================\n",
    "\n",
    "final_val_pred = (val_probs >= BEST_T).astype(int)\n",
    "\n",
    "print(\"\\nüìä CLASSIFICATION REPORT (VALIDATION SET)\")\n",
    "print(classification_report(y_val, final_val_pred, digits=4))\n",
    "print(\"üìâ CONFUSION MATRIX\")\n",
    "print(confusion_matrix(y_val, final_val_pred))\n",
    "\n",
    "# ======================================================\n",
    "# 9Ô∏è‚É£ SALVATAGGIO PER PRODUZIONE\n",
    "# ======================================================\n",
    "\n",
    "print(f\"\\nüíæ Salvataggio modello per produzione in '{OUTPUT_MODEL_NAME}'...\")\n",
    "\n",
    "production_bundle = {\n",
    "    \"rf_model\": rf,             # Modello fittato su tutto X_train\n",
    "    \"xgb_model\": xgb,           # Modello fittato su tutto X_train\n",
    "    \"lgbm_model\": lgbm,         # Modello fittato su tutto X_train\n",
    "    \"meta_model\": meta_model,   # Modello fittato sulle meta-features\n",
    "    \"threshold\": BEST_T,        # La soglia che abbiamo trovato\n",
    "    \"features_order\": X_train.columns.tolist() # Ordine colonne per sicurezza\n",
    "}\n",
    "\n",
    "joblib.dump(production_bundle, OUTPUT_MODEL_NAME)\n",
    "\n",
    "print(\"‚úÖ DONE! Il file .pkl √® pronto per essere usato in produzione.\")"
   ],
   "id": "fc3379be5f62e0d9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Caricamento dataset...\n",
      "‚úÖ Dati caricati. Scale Pos Weight calcolato: 6.79\n",
      "\n",
      "‚öôÔ∏è AVVIO TUNING (n_iter=10)... attendere...\n",
      "   ...Tuning Random Forest...\n",
      "   ‚úÖ Best RF Params: {'n_estimators': 300, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_depth': 30, 'class_weight': 'balanced_subsample'}\n",
      "   ...Tuning XGBoost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marcodonatiello/PycharmProjects/JupyterProject/.venv/lib/python3.14/site-packages/xgboost/training.py:199: UserWarning: [20:58:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/marcodonatiello/PycharmProjects/JupyterProject/.venv/lib/python3.14/site-packages/xgboost/training.py:199: UserWarning: [20:58:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/marcodonatiello/PycharmProjects/JupyterProject/.venv/lib/python3.14/site-packages/xgboost/training.py:199: UserWarning: [20:58:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/marcodonatiello/PycharmProjects/JupyterProject/.venv/lib/python3.14/site-packages/xgboost/training.py:199: UserWarning: [20:58:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/marcodonatiello/PycharmProjects/JupyterProject/.venv/lib/python3.14/site-packages/xgboost/training.py:199: UserWarning: [20:58:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/marcodonatiello/PycharmProjects/JupyterProject/.venv/lib/python3.14/site-packages/xgboost/training.py:199: UserWarning: [20:58:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/marcodonatiello/PycharmProjects/JupyterProject/.venv/lib/python3.14/site-packages/xgboost/training.py:199: UserWarning: [20:58:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/marcodonatiello/PycharmProjects/JupyterProject/.venv/lib/python3.14/site-packages/xgboost/training.py:199: UserWarning: [20:58:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/marcodonatiello/PycharmProjects/JupyterProject/.venv/lib/python3.14/site-packages/xgboost/training.py:199: UserWarning: [20:58:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/marcodonatiello/PycharmProjects/JupyterProject/.venv/lib/python3.14/site-packages/xgboost/training.py:199: UserWarning: [20:58:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/marcodonatiello/PycharmProjects/JupyterProject/.venv/lib/python3.14/site-packages/xgboost/training.py:199: UserWarning: [20:59:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/marcodonatiello/PycharmProjects/JupyterProject/.venv/lib/python3.14/site-packages/xgboost/training.py:199: UserWarning: [20:59:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/marcodonatiello/PycharmProjects/JupyterProject/.venv/lib/python3.14/site-packages/xgboost/training.py:199: UserWarning: [20:59:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/marcodonatiello/PycharmProjects/JupyterProject/.venv/lib/python3.14/site-packages/xgboost/training.py:199: UserWarning: [20:59:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/marcodonatiello/PycharmProjects/JupyterProject/.venv/lib/python3.14/site-packages/xgboost/training.py:199: UserWarning: [20:59:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/marcodonatiello/PycharmProjects/JupyterProject/.venv/lib/python3.14/site-packages/xgboost/training.py:199: UserWarning: [20:59:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/marcodonatiello/PycharmProjects/JupyterProject/.venv/lib/python3.14/site-packages/xgboost/training.py:199: UserWarning: [20:59:09] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/marcodonatiello/PycharmProjects/JupyterProject/.venv/lib/python3.14/site-packages/xgboost/training.py:199: UserWarning: [20:59:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/marcodonatiello/PycharmProjects/JupyterProject/.venv/lib/python3.14/site-packages/xgboost/training.py:199: UserWarning: [20:59:20] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/marcodonatiello/PycharmProjects/JupyterProject/.venv/lib/python3.14/site-packages/xgboost/training.py:199: UserWarning: [20:59:23] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/marcodonatiello/PycharmProjects/JupyterProject/.venv/lib/python3.14/site-packages/xgboost/training.py:199: UserWarning: [20:59:23] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/marcodonatiello/PycharmProjects/JupyterProject/.venv/lib/python3.14/site-packages/xgboost/training.py:199: UserWarning: [20:59:30] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/marcodonatiello/PycharmProjects/JupyterProject/.venv/lib/python3.14/site-packages/xgboost/training.py:199: UserWarning: [20:59:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/marcodonatiello/PycharmProjects/JupyterProject/.venv/lib/python3.14/site-packages/xgboost/training.py:199: UserWarning: [20:59:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/marcodonatiello/PycharmProjects/JupyterProject/.venv/lib/python3.14/site-packages/xgboost/training.py:199: UserWarning: [20:59:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/marcodonatiello/PycharmProjects/JupyterProject/.venv/lib/python3.14/site-packages/xgboost/training.py:199: UserWarning: [20:59:34] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/marcodonatiello/PycharmProjects/JupyterProject/.venv/lib/python3.14/site-packages/xgboost/training.py:199: UserWarning: [20:59:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/marcodonatiello/PycharmProjects/JupyterProject/.venv/lib/python3.14/site-packages/xgboost/training.py:199: UserWarning: [20:59:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/marcodonatiello/PycharmProjects/JupyterProject/.venv/lib/python3.14/site-packages/xgboost/training.py:199: UserWarning: [20:59:40] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/marcodonatiello/PycharmProjects/JupyterProject/.venv/lib/python3.14/site-packages/xgboost/training.py:199: UserWarning: [20:59:41] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/marcodonatiello/PycharmProjects/JupyterProject/.venv/lib/python3.14/site-packages/xgboost/training.py:199: UserWarning: [20:59:58] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ Best XGB Params: {'subsample': 0.6, 'scale_pos_weight': np.float64(6.786794808513109), 'n_estimators': 500, 'max_depth': 6, 'learning_rate': 0.2, 'colsample_bytree': 0.8}\n",
      "   ...Tuning LightGBM...\n",
      "   ‚úÖ Best LGBM Params: {'subsample': 0.9, 'num_leaves': 64, 'n_estimators': 600, 'max_depth': 20, 'learning_rate': 0.1, 'colsample_bytree': 0.8, 'class_weight': 'balanced'}\n",
      "\n",
      "üöÄ Inizializzazione modelli con i parametri migliori...\n",
      "\n",
      "üîÑ Generazione OOF meta-features (Training Livello 0)...\n",
      "   -> Fold 1/5 completato\n",
      "   -> Fold 2/5 completato\n",
      "   -> Fold 3/5 completato\n",
      "   -> Fold 4/5 completato\n",
      "   -> Fold 5/5 completato\n",
      "\n",
      "üèãÔ∏è Addestramento modelli base su tutto il dataset...\n",
      "‚úÖ Meta-model addestrato\n",
      "\n",
      "üèÜ BEST THRESHOLD: 0.60 (F1-Score: 0.5886)\n",
      "\n",
      "üìä CLASSIFICATION REPORT (VALIDATION SET)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9644    0.8712    0.9154    116872\n",
      "           1     0.4721    0.7814    0.5886     17221\n",
      "\n",
      "    accuracy                         0.8597    134093\n",
      "   macro avg     0.7182    0.8263    0.7520    134093\n",
      "weighted avg     0.9011    0.8597    0.8735    134093\n",
      "\n",
      "üìâ CONFUSION MATRIX\n",
      "[[101824  15048]\n",
      " [  3764  13457]]\n",
      "\n",
      "üíæ Salvataggio modello per produzione in 'severe_model_stacking_production.pkl'...\n",
      "‚úÖ DONE! Il file .pkl √® pronto per essere usato in produzione.\n"
     ]
    }
   ],
   "execution_count": 1
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
