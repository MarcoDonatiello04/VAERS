{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-30T20:50:03.106614Z",
     "iopub.status.busy": "2026-01-30T20:50:03.106371Z",
     "iopub.status.idle": "2026-01-30T20:50:03.872450Z",
     "shell.execute_reply": "2026-01-30T20:50:03.872051Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, confusion_matrix, classification_report, roc_curve\n",
    ")\n",
    "import os\n",
    "\n",
    "# Configurazione\n",
    "BASE_DIR = os.path.dirname(os.getcwd())\n",
    "DATA_DIR = os.path.join(BASE_DIR, 'dataset')\n",
    "MODEL_DIR = os.getcwd()\n",
    "\n",
    "TEST_PATH = os.path.join(DATA_DIR, 'test_step6.csv')\n",
    "MODEL_PATH = os.path.join(MODEL_DIR, 'severe_model_stacking_production.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-30T20:50:03.873874Z",
     "iopub.status.busy": "2026-01-30T20:50:03.873763Z",
     "iopub.status.idle": "2026-01-30T20:50:04.598057Z",
     "shell.execute_reply": "2026-01-30T20:50:04.597719Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dizionario modello caricato. Keys: dict_keys(['rf_model', 'xgb_model', 'lgbm_model', 'meta_model', 'threshold', 'features_order'])\n",
      "Threshold salvato: 0.5999999999999999\n"
     ]
    }
   ],
   "source": [
    "# Caricamento\n",
    "df_test = pd.read_csv(TEST_PATH)\n",
    "model_dict = joblib.load(MODEL_PATH)\n",
    "print(\"Dizionario modello caricato. Keys:\", model_dict.keys())\n",
    "\n",
    "# Estrazione Componenti\n",
    "rf_model = model_dict['rf_model']\n",
    "xgb_model = model_dict['xgb_model']\n",
    "lgbm_model = model_dict['lgbm_model']\n",
    "meta_model = model_dict['meta_model']\n",
    "threshold = model_dict.get('threshold', 0.5)\n",
    "features_order = model_dict.get('features_order', None)\n",
    "\n",
    "print(f\"Threshold salvato: {threshold}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-30T20:50:04.599463Z",
     "iopub.status.busy": "2026-01-30T20:50:04.599403Z",
     "iopub.status.idle": "2026-01-30T20:50:04.602289Z",
     "shell.execute_reply": "2026-01-30T20:50:04.601985Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features allineate secondo 'features_order'.\n"
     ]
    }
   ],
   "source": [
    "# Preparazione Dati\n",
    "target_col = 'IS_SEVERE'\n",
    "X_test = df_test.drop(columns=[target_col])\n",
    "y_test = df_test[target_col]\n",
    "\n",
    "# Allineamento Features\n",
    "if features_order is not None:\n",
    "    # Check missing\n",
    "    missing = set(features_order) - set(X_test.columns)\n",
    "    for c in missing:\n",
    "        X_test[c] = 0\n",
    "    X_test = X_test[features_order]\n",
    "    print(\"Features allineate secondo 'features_order'.\")\n",
    "else:\n",
    "    print(\"ATTENZIONE: 'features_order' non trovato. Uso l'ordine del dataframe.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-30T20:50:04.603364Z",
     "iopub.status.busy": "2026-01-30T20:50:04.603315Z",
     "iopub.status.idle": "2026-01-30T20:50:06.087328Z",
     "shell.execute_reply": "2026-01-30T20:50:06.086903Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generazione predizioni base models...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features attese dal meta model: ['rf_prob' 'xgb_prob' 'lgbm_prob']\n",
      "Predizione stacking completata.\n"
     ]
    }
   ],
   "source": [
    "# Infeernza Base Models\n",
    "print(\"Generazione predizioni base models...\")\n",
    "p_rf = rf_model.predict_proba(X_test)[:, 1]\n",
    "p_xgb = xgb_model.predict_proba(X_test)[:, 1]\n",
    "p_lgbm = lgbm_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Stacking\n",
    "# L'ordine deve essere coerente con come è stato trainato il meta model.\n",
    "# Cerchiamo di dedurlo dai feature_names_in_ del meta_model se possibile\n",
    "X_meta = None\n",
    "if hasattr(meta_model, 'feature_names_in_'):\n",
    "    meta_features = meta_model.feature_names_in_\n",
    "    print(\"Features attese dal meta model:\", meta_features)\n",
    "    # Creiamo un dataframe per essere sicuri\n",
    "    df_meta = pd.DataFrame({\n",
    "        'rf': p_rf, # Possibili nomi, da verificare\n",
    "        'xgb': p_xgb,\n",
    "        'lgbm': p_lgbm,\n",
    "        'RF': p_rf,\n",
    "        'XGB': p_xgb,\n",
    "        'LGBM': p_lgbm\n",
    "    })\n",
    "    # Proviamo a selezionare quelle che matchano\n",
    "    # Spesso i nomi sono generici o 'rf_pred', ecc. \n",
    "    # Se fallisce, usiamo l'ordine standard [rf, xgb, lgbm]\n",
    "    try:\n",
    "         X_meta_df = pd.DataFrame()\n",
    "         for feat in meta_features:\n",
    "             # Euristica base per mappare nomi features\n",
    "             if 'rf' in feat.lower(): X_meta_df[feat] = p_rf\n",
    "             elif 'xgb' in feat.lower(): X_meta_df[feat] = p_xgb\n",
    "             elif 'lgb' in feat.lower(): X_meta_df[feat] = p_lgbm\n",
    "         X_meta = X_meta_df\n",
    "    except:\n",
    "        X_meta = np.column_stack((p_rf, p_xgb, p_lgbm))   \n",
    "else:\n",
    "    # Fallback ordine standard\n",
    "    X_meta = np.column_stack((p_rf, p_xgb, p_lgbm))\n",
    "\n",
    "# Se X_meta è vuoto o ha colonne sbagliate (succede se euristica fallisce), fallback\n",
    "if isinstance(X_meta, pd.DataFrame) and X_meta.shape[1] != 3:\n",
    "    print(\"Euristica nomi fallita, uso ordine sequenziale [rf, xgb, lgbm]\")\n",
    "    X_meta = np.column_stack((p_rf, p_xgb, p_lgbm))\n",
    "elif X_meta is None:\n",
    "     X_meta = np.column_stack((p_rf, p_xgb, p_lgbm))\n",
    "\n",
    "\n",
    "# Predizione Finale\n",
    "y_prob = meta_model.predict_proba(X_meta)[:, 1]\n",
    "y_pred = (y_prob >= threshold).astype(int)\n",
    "\n",
    "print(\"Predizione stacking completata.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-30T20:50:06.088549Z",
     "iopub.status.busy": "2026-01-30T20:50:06.088476Z",
     "iopub.status.idle": "2026-01-30T20:50:06.154151Z",
     "shell.execute_reply": "2026-01-30T20:50:06.153828Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      " REPORT STACKING MODEL\n",
      "==================================================\n",
      "ACCURACY:  0.8050\n",
      "PRECISION: 0.3797\n",
      "RECALL:    0.8180\n",
      "F1-SCORE:  0.5186\n",
      "ROC-AUC:   0.8910\n",
      "--------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.80      0.88    146090\n",
      "           1       0.38      0.82      0.52     21526\n",
      "\n",
      "    accuracy                           0.81    167616\n",
      "   macro avg       0.67      0.81      0.70    167616\n",
      "weighted avg       0.89      0.81      0.83    167616\n",
      "\n",
      "TP: 17608, FP: 28766, TN: 117324, FN: 3918\n"
     ]
    }
   ],
   "source": [
    "# Metriche\n",
    "print(\"=\"*50)\n",
    "print(\" REPORT STACKING MODEL\")\n",
    "print(\"=\"*50)\n",
    "print(f\"ACCURACY:  {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(f\"PRECISION: {precision_score(y_test, y_pred):.4f}\")\n",
    "print(f\"RECALL:    {recall_score(y_test, y_pred):.4f}\")\n",
    "print(f\"F1-SCORE:  {f1_score(y_test, y_pred):.4f}\")\n",
    "print(f\"ROC-AUC:   {roc_auc_score(y_test, y_prob):.4f}\")\n",
    "print(\"-\"*50)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "print(f\"TP: {tp}, FP: {fp}, TN: {tn}, FN: {fn}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
